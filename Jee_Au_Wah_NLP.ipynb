{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JeeAu/NLP_Project/blob/main/Jee_Au_Wah_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rp7MxnFefw0L"
      },
      "outputs": [],
      "source": [
        "pip install jupyterlab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xmH58Mk66F19"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "print(\"PyTorch version:\", torch.__version__)\n",
        "print(\"CUDA version (compiled):\", torch.version.cuda)\n",
        "print(\"Current GPU device:\", torch.cuda.current_device() if torch.cuda.is_available() else \"No GPU detected\")\n",
        "print(\"GPU Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"N/A\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TQVpikoGU7El"
      },
      "outputs": [],
      "source": [
        "# First uninstall the problematic packages\n",
        "!pip uninstall -y huggingface_hub transformers accelerate bertopic\n",
        "\n",
        "# Install specific compatible versions in the right order\n",
        "!pip install huggingface_hub==0.24.0\n",
        "!pip install tokenizers==0.15.2\n",
        "!pip install transformers==4.35.2\n",
        "!pip install accelerate==0.25.0\n",
        "!pip install datasets==2.16.0  # Older version compatible with huggingface_hub 0.24.0\n",
        "!pip install bertopic==0.16.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J7Yo23dg-VkW"
      },
      "outputs": [],
      "source": [
        "pip show huggingface_hub transformers accelerate bertopic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxhltw7M-bN-"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade accelerate\n",
        "# Install remaining dependencies (excluding already installed packages)\n",
        "!pip install swifter umap-learn hdbscan sentence-transformers\n",
        "!pip install pandas numpy matplotlib seaborn nltk scikit-learn\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import gc\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# NLP and Text Processing\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Parallel processing\n",
        "import swifter\n",
        "\n",
        "# Dimensionality reduction and clustering\n",
        "from umap import UMAP\n",
        "import hdbscan\n",
        "\n",
        "# Topic Modeling\n",
        "from bertopic import BERTopic\n",
        "\n",
        "# Machine Learning\n",
        "from sklearn.utils import resample\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Text embeddings\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# PyTorch for custom model if needed\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "RANDOM_SEED = 42\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "np.random.seed(RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPPXCYLRU2gq",
        "outputId": "248534a9-a92b-4b70-bb18-c4173c785a46"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------\n",
            "Office Products Customer Feedback Analysis\n",
            "-----------------------------------\n",
            "--2025-09-22 14:47:07--  https://jmcauley.ucsd.edu/data/amazon_v2/categoryFilesSmall/Office_Products_5.json.gz\n",
            "Resolving jmcauley.ucsd.edu (jmcauley.ucsd.edu)... 137.110.160.73\n",
            "Connecting to jmcauley.ucsd.edu (jmcauley.ucsd.edu)|137.110.160.73|:443... connected.\n",
            "WARNING: cannot verify jmcauley.ucsd.edu's certificate, issued by ‘CN=InCommon RSA Server CA 2,O=Internet2,C=US’:\n",
            "  Unable to locally verify the issuer's authority.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 111685374 (107M) [application/x-gzip]\n",
            "Saving to: ‘Office_Products_5.json.gz’\n",
            "\n",
            "Office_Products_5.j 100%[===================>] 106.51M  20.0MB/s    in 4.4s    \n",
            "\n",
            "2025-09-22 14:47:12 (24.0 MB/s) - ‘Office_Products_5.json.gz’ saved [111685374/111685374]\n",
            "\n",
            "gzip: Office_Products_5.json already exists; do you wish to overwrite (y or n)? "
          ]
        }
      ],
      "source": [
        "print(\"-----------------------------------\")\n",
        "print(\"Office Products Customer Feedback Analysis\")\n",
        "print(\"-----------------------------------\")\n",
        "\n",
        "# ----------------------\n",
        "# DOWNLOAD AND LOAD DATA\n",
        "# ----------------------\n",
        "!wget --no-check-certificate https://jmcauley.ucsd.edu/data/amazon_v2/categoryFilesSmall/Office_Products_5.json.gz\n",
        "!gzip -d Office_Products_5.json.gz\n",
        "\n",
        "chunk_size = 100000\n",
        "chunks = pd.read_json('Office_Products_5.json', lines=True, chunksize=chunk_size)\n",
        "df = pd.concat(chunks)\n",
        "df = df[['reviewText', 'overall', 'summary', 'reviewTime']].dropna()\n",
        "print(f\"Loaded {len(df)} reviews. Columns: {df.columns}\")\n",
        "\n",
        "# Convert reviewTime to datetime\n",
        "df['reviewTime'] = pd.to_datetime(df['reviewTime'], format='%m %d, %Y', errors='coerce')\n",
        "\n",
        "# Initialize NLP tools\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    \"\"\"Clean and normalize text\"\"\"\n",
        "    text = re.sub(r'<.*?>|[^a-zA-Z\\s]', '', str(text))\n",
        "    text = text.lower().strip()\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in text.split() if word not in stop_words and len(word) > 2]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# Apply preprocessing in batches using swifter for parallel processing\n",
        "print(\"Preprocessing review text...\")\n",
        "df['cleaned_review'] = df['reviewText'].swifter.apply(preprocess_text)\n",
        "df = df.drop(columns=['reviewText'])  # Free memory\n",
        "\n",
        "# Exploratory Data Analysis (EDA)\n",
        "print(\"Generating EDA visualizations...\")\n",
        "\n",
        "# Plot rating distribution\n",
        "plt.figure(figsize=(10, 6))\n",
        "rating_counts = df['overall'].value_counts().sort_index()\n",
        "sns.barplot(x=rating_counts.index, y=rating_counts.values, palette='viridis')\n",
        "plt.title('Rating Distribution (1-5 Stars)', fontsize=15)\n",
        "plt.xlabel('Rating')\n",
        "plt.ylabel('Count')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.savefig('rating_distribution.png')\n",
        "plt.show()\n",
        "\n",
        "# Analyze review length\n",
        "df['review_length'] = df['cleaned_review'].apply(lambda x: len(x.split()))\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(df['review_length'], bins=50, color='teal', alpha=0.7)\n",
        "plt.title('Distribution of Review Lengths', fontsize=15)\n",
        "plt.xlabel('Word Count')\n",
        "plt.ylabel('Frequency')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.savefig('review_length_distribution.png')\n",
        "plt.show()\n",
        "\n",
        "# Year-wise review count\n",
        "df['review_year'] = df['reviewTime'].dt.year\n",
        "year_counts = df['review_year'].value_counts().sort_index()\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.lineplot(x=year_counts.index, y=year_counts.values, marker='o', linewidth=2)\n",
        "plt.title('Reviews by Year', fontsize=15)\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Number of Reviews')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.savefig('yearly_review_count.png')\n",
        "plt.show()\n",
        "\n",
        "# Rating distribution over time\n",
        "yearly_ratings = df.groupby('review_year')['overall'].mean().reset_index()\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.lineplot(x='review_year', y='overall', data=yearly_ratings, marker='o', linewidth=2)\n",
        "plt.title('Average Rating by Year', fontsize=15)\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Average Rating')\n",
        "plt.ylim(1, 5)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.savefig('yearly_rating_trend.png')\n",
        "plt.show()\n",
        "\n",
        "# Take a sample for further analysis to avoid memory issues\n",
        "SAMPLE_SIZE = 10000\n",
        "print(f\"Taking a sample of {SAMPLE_SIZE} reviews for detailed analysis...\")\n",
        "sample_df = df.sample(SAMPLE_SIZE, random_state=RANDOM_SEED).copy()\n",
        "del df\n",
        "gc.collect()\n",
        "\n",
        "# Topic Modeling with BERTopic\n",
        "print(\"Running BERTopic model for topic discovery...\")\n",
        "umap_model = UMAP(n_components=5, n_neighbors=15, min_dist=0.0, metric='cosine', low_memory=True, random_state=RANDOM_SEED)\n",
        "hdbscan_model = hdbscan.HDBSCAN(min_cluster_size=20, metric='euclidean', cluster_selection_method='eom', prediction_data=True)\n",
        "topic_model = BERTopic(embedding_model=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
        "                       language=\"english\",\n",
        "                       calculate_probabilities=False,\n",
        "                       min_topic_size=20,\n",
        "                       nr_topics=\"auto\",\n",
        "                       umap_model=umap_model,\n",
        "                       hdbscan_model=hdbscan_model,\n",
        "                       verbose=True)\n",
        "\n",
        "topics, probs = topic_model.fit_transform(sample_df['cleaned_review'])\n",
        "sample_df['topic'] = topics\n",
        "\n",
        "# Visualize topics\n",
        "print(\"Visualizing discovered topics...\")\n",
        "fig = topic_model.visualize_topics()\n",
        "fig.write_html(\"topics_visualization.html\")\n",
        "plt.figure(figsize=(12, 8))\n",
        "topic_model.visualize_barchart(top_n_topics=10).show()\n",
        "\n",
        "# Get topic information\n",
        "topic_info = topic_model.get_topic_info()\n",
        "print(\"\\nTop 10 Topics by Size:\")\n",
        "print(topic_info.head(10))\n",
        "\n",
        "# Display top terms for each topic\n",
        "print(\"\\nTop 5 Terms for Each Topic:\")\n",
        "for topic_id in topic_info['Topic'][:10]:\n",
        "    if topic_id != -1:  # Skip outlier topic\n",
        "        topic_terms = topic_model.get_topic(topic_id)\n",
        "        terms = \", \".join([term for term, _ in topic_terms[:5]])\n",
        "        print(f\"Topic {topic_id}: {terms}\")\n",
        "\n",
        "# Sentiment Analysis\n",
        "print(\"\\nPerforming sentiment analysis...\")\n",
        "vader = SentimentIntensityAnalyzer()\n",
        "sample_df['vader_score'] = sample_df['cleaned_review'].apply(lambda x: vader.polarity_scores(x)['compound'])\n",
        "\n",
        "def label_sentiment(rating):\n",
        "    if rating <= 2:\n",
        "        return 0  # negative\n",
        "    elif rating == 3:\n",
        "        return 1  # neutral\n",
        "    else:\n",
        "        return 2  # positive\n",
        "\n",
        "sample_df['sentiment_label'] = sample_df['overall'].apply(label_sentiment)\n",
        "\n",
        "# Display sentiment distribution\n",
        "plt.figure(figsize=(8, 6))\n",
        "sentiment_counts = sample_df['sentiment_label'].map({0:'Negative', 1:'Neutral', 2:'Positive'}).value_counts()\n",
        "sns.barplot(x=sentiment_counts.index, y=sentiment_counts.values, palette='RdYlGn')\n",
        "plt.title('Sentiment Distribution', fontsize=15)\n",
        "plt.xlabel('Sentiment')\n",
        "plt.ylabel('Count')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.savefig('sentiment_distribution.png')\n",
        "plt.show()\n",
        "\n",
        "# Balance classes for training\n",
        "print(\"Balancing dataset for sentiment classification...\")\n",
        "df_majority = sample_df[sample_df['sentiment_label'] == 2]\n",
        "df_minority_neg = sample_df[sample_df['sentiment_label'] == 0]\n",
        "df_minority_neu = sample_df[sample_df['sentiment_label'] == 1]\n",
        "\n",
        "n_samples = min(len(df_majority), 1000)\n",
        "df_minority_neg_upsampled = resample(df_minority_neg, replace=True, n_samples=n_samples, random_state=RANDOM_SEED)\n",
        "df_minority_neu_upsampled = resample(df_minority_neu, replace=True, n_samples=n_samples, random_state=RANDOM_SEED)\n",
        "balanced_df = pd.concat([df_majority.sample(n=n_samples, random_state=RANDOM_SEED),\n",
        "                         df_minority_neg_upsampled,\n",
        "                         df_minority_neu_upsampled])\n",
        "balanced_df = balanced_df.sample(frac=1, random_state=RANDOM_SEED).reset_index(drop=True)\n",
        "\n",
        "print(f\"Balanced dataset sizes - Positive: {n_samples}, Neutral: {n_samples}, Negative: {n_samples}\")\n",
        "\n",
        "# Create embeddings using sentence-transformers\n",
        "print(\"\\nGenerating embeddings for sentiment analysis...\")\n",
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "def get_embeddings(texts, batch_size=32):\n",
        "    return embedding_model.encode(texts, batch_size=batch_size, show_progress_bar=True)\n",
        "\n",
        "# Generate embeddings for the balanced dataset\n",
        "embeddings = get_embeddings(balanced_df['cleaned_review'].tolist())\n",
        "\n",
        "# Split data for sentiment classification\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    embeddings,\n",
        "    balanced_df['sentiment_label'].values,\n",
        "    test_size=0.2,\n",
        "    random_state=RANDOM_SEED,\n",
        "    stratify=balanced_df['sentiment_label']\n",
        ")\n",
        "\n",
        "# Train a simple classifier on embeddings\n",
        "print(\"\\nTraining logistic regression for sentiment classification...\")\n",
        "clf = LogisticRegression(C=1.0, max_iter=1000, class_weight='balanced', random_state=RANDOM_SEED)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = clf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(f\"\\nLogistic Regression Results:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=['Negative', 'Neutral', 'Positive']))\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Negative', 'Neutral', 'Positive'],\n",
        "            yticklabels=['Negative', 'Neutral', 'Positive'])\n",
        "plt.title('Confusion Matrix', fontsize=15)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.savefig('confusion_matrix.png')\n",
        "plt.show()\n",
        "\n",
        "# Analyze topics related to sentiment\n",
        "print(\"\\nAnalyzing topics by sentiment...\")\n",
        "topic_sentiment = sample_df.groupby('topic')['vader_score'].mean().sort_values(ascending=False)\n",
        "print(\"\\nTopics by average sentiment score (highest to lowest):\")\n",
        "for topic_id, score in topic_sentiment.items():\n",
        "    if topic_id != -1:  # Skip outlier topic\n",
        "        topic_words = topic_model.get_topic(topic_id)\n",
        "        topic_words_str = \", \".join([word for word, _ in topic_words[:5]])\n",
        "        print(f\"Topic {topic_id} ({topic_words_str}): {score:.3f}\")\n",
        "\n",
        "# Visualize topic-sentiment relationship\n",
        "plt.figure(figsize=(12, 6))\n",
        "topic_sentiment = topic_sentiment[topic_sentiment.index != -1]  # Remove outlier topic\n",
        "topic_sentiment_df = pd.DataFrame({'Topic': topic_sentiment.index, 'Sentiment': topic_sentiment.values})\n",
        "topic_sentiment_df = topic_sentiment_df.sort_values('Sentiment', ascending=False)\n",
        "\n",
        "# Get topic words for the x labels\n",
        "topic_labels = []\n",
        "for topic_id in topic_sentiment_df['Topic']:\n",
        "    words = [word for word, _ in topic_model.get_topic(topic_id)[:2]]\n",
        "    topic_labels.append(f\"{topic_id}: {', '.join(words)}\")\n",
        "\n",
        "# Plot with readable topic labels\n",
        "plt.figure(figsize=(14, 8))\n",
        "bar_plot = sns.barplot(x='Topic', y='Sentiment', data=topic_sentiment_df, palette='RdYlGn_r')\n",
        "plt.title('Average Sentiment Score by Topic', fontsize=15)\n",
        "plt.xlabel('Topic ID and Key Terms')\n",
        "plt.ylabel('Average Sentiment Score')\n",
        "plt.xticks(range(len(topic_labels)), topic_labels, rotation=45, ha='right')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig('topic_sentiment.png')\n",
        "plt.show()\n",
        "\n",
        "# Save key insights to CSV files\n",
        "print(\"\\nSaving analysis results to files...\")\n",
        "\n",
        "# Save topic information\n",
        "topic_info.to_csv('topic_info.csv')\n",
        "\n",
        "# Save sentiment by topic\n",
        "topic_sentiment_df.to_csv('topic_sentiment.csv')\n",
        "\n",
        "# Create a dataframe with example reviews for each topic\n",
        "topic_examples = []\n",
        "for topic_id in topic_info['Topic'][:15]:  # Top 15 topics\n",
        "    if topic_id == -1:\n",
        "        continue\n",
        "    # Get 3 example reviews for this topic\n",
        "    examples = sample_df[sample_df['topic'] == topic_id].sort_values('vader_score', ascending=False).head(3)\n",
        "    for _, row in examples.iterrows():\n",
        "        topic_examples.append({\n",
        "            'Topic': topic_id,\n",
        "            'Sentiment': row['vader_score'],\n",
        "            'Rating': row['overall'],\n",
        "            'Review': row['cleaned_review'][:200] + '...'  # First 200 chars\n",
        "        })\n",
        "\n",
        "# Save examples to CSV\n",
        "pd.DataFrame(topic_examples).to_csv('topic_examples.csv')\n",
        "\n",
        "print(\"\\nAnalysis complete! Results saved to CSV files and visualizations saved as PNG files.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXjywGYqr5Cv"
      },
      "outputs": [],
      "source": [
        "# Install required PyTorch-related libraries\n",
        "!pip install torch torchvision torchaudio\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# 1. Encode labels (negative=0, neutral=1, positive=2)\n",
        "label_encoder = LabelEncoder()\n",
        "balanced_df['label'] = label_encoder.fit_transform(balanced_df['sentiment_label'])\n",
        "\n",
        "# 2. PyTorch Dataset\n",
        "class ReviewDataset(Dataset):\n",
        "    def __init__(self, embeddings, labels):\n",
        "        self.embeddings = torch.tensor(embeddings, dtype=torch.float32)\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.embeddings[idx], self.labels[idx]\n",
        "\n",
        "dataset = ReviewDataset(embeddings, balanced_df['label'].values)\n",
        "\n",
        "# Split dataset\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# 3. Define the Variational Autoencoder\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self, input_dim=384, latent_dim=64):\n",
        "        super(VAE, self).__init__()\n",
        "        # Encoder\n",
        "        self.fc1 = nn.Linear(input_dim, 256)\n",
        "        self.fc_mu = nn.Linear(256, latent_dim)\n",
        "        self.fc_logvar = nn.Linear(256, latent_dim)\n",
        "\n",
        "        # Decoder\n",
        "        self.fc3 = nn.Linear(latent_dim, 256)\n",
        "        self.fc4 = nn.Linear(256, input_dim)\n",
        "\n",
        "    def encode(self, x):\n",
        "        h1 = F.relu(self.fc1(x))\n",
        "        return self.fc_mu(h1), self.fc_logvar(h1)\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5*logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def decode(self, z):\n",
        "        h3 = F.relu(self.fc3(z))\n",
        "        return self.fc4(h3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        x_recon = self.decode(z)\n",
        "        return x_recon, mu, logvar\n",
        "\n",
        "# 4. VAE Loss\n",
        "def vae_loss(recon_x, x, mu, logvar):\n",
        "    recon_loss = F.mse_loss(recon_x, x, reduction='sum')\n",
        "    kld = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    return recon_loss + kld\n",
        "\n",
        "# 5. Train the VAE\n",
        "vae = VAE()\n",
        "optimizer = torch.optim.Adam(vae.parameters(), lr=1e-3)\n",
        "\n",
        "vae.train()\n",
        "for epoch in range(10):\n",
        "    total_loss = 0\n",
        "    for batch in train_loader:\n",
        "        inputs, _ = batch\n",
        "        optimizer.zero_grad()\n",
        "        recon_x, mu, logvar = vae(inputs)\n",
        "        loss = vae_loss(recon_x, inputs, mu, logvar)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}: Loss = {total_loss/len(train_loader.dataset):.4f}\")\n",
        "\n",
        "# 6. Extract latent vectors for classification\n",
        "vae.eval()\n",
        "def extract_latents(dataloader):\n",
        "    all_latents = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            mu, _ = vae.encode(inputs)\n",
        "            all_latents.append(mu)\n",
        "            all_labels.append(labels)\n",
        "    return torch.cat(all_latents), torch.cat(all_labels)\n",
        "\n",
        "X_train_latent, y_train_latent = extract_latents(train_loader)\n",
        "X_val_latent, y_val_latent = extract_latents(val_loader)\n",
        "\n",
        "# 7. Train a simple classifier on latent vectors\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "clf = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=RANDOM_SEED)\n",
        "clf.fit(X_train_latent.numpy(), y_train_latent.numpy())\n",
        "\n",
        "# 8. Evaluate classifier\n",
        "y_pred = clf.predict(X_val_latent.numpy())\n",
        "accuracy = accuracy_score(y_val_latent.numpy(), y_pred)\n",
        "f1 = f1_score(y_val_latent.numpy(), y_pred, average='weighted')\n",
        "\n",
        "print(f\"\\nVAE + Logistic Regression Results:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_val_latent.numpy(), y_pred, target_names=['Negative', 'Neutral', 'Positive']))\n",
        "\n",
        "# Confusion Matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "conf_matrix = confusion_matrix(y_val_latent.numpy(), y_pred)\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='coolwarm',\n",
        "            xticklabels=['Negative', 'Neutral', 'Positive'],\n",
        "            yticklabels=['Negative', 'Neutral', 'Positive'])\n",
        "plt.title('Confusion Matrix (VAE)', fontsize=15)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.tight_layout()\n",
        "plt.savefig('vae_confusion_matrix.png')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3dK57bA2twNn"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
        "\n",
        "print(\"\\nGenerating TF-IDF vectors and applying LSA...\")\n",
        "\n",
        "# Step 1: TF-IDF vectorization\n",
        "tfidf_vectorizer = TfidfVectorizer(\n",
        "    max_df=0.9,\n",
        "    min_df=5,\n",
        "    max_features=5000,\n",
        "    stop_words='english'\n",
        ")\n",
        "\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(balanced_df['cleaned_review'])\n",
        "\n",
        "# Step 2: Apply LSA using TruncatedSVD\n",
        "n_components = 100  # Latent dimensions\n",
        "svd = TruncatedSVD(n_components=n_components, random_state=RANDOM_SEED)\n",
        "X_lsa = svd.fit_transform(X_tfidf)\n",
        "\n",
        "print(f\"LSA reduced TF-IDF shape: {X_lsa.shape}\")\n",
        "\n",
        "# Step 3: Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_lsa,\n",
        "    balanced_df['sentiment_label'].values,\n",
        "    test_size=0.2,\n",
        "    random_state=RANDOM_SEED,\n",
        "    stratify=balanced_df['sentiment_label']\n",
        ")\n",
        "\n",
        "# Step 4: Train classifier on LSA-reduced features\n",
        "print(\"\\nTraining Logistic Regression on LSA features...\")\n",
        "clf = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=RANDOM_SEED)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Step 5: Evaluate model\n",
        "y_pred = clf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(f\"\\nLSA + Logistic Regression Results:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=['Negative', 'Neutral', 'Positive']))\n",
        "\n",
        "# Step 6: Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='YlGnBu',\n",
        "            xticklabels=['Negative', 'Neutral', 'Positive'],\n",
        "            yticklabels=['Negative', 'Neutral', 'Positive'])\n",
        "plt.title('Confusion Matrix (LSA)', fontsize=15)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.tight_layout()\n",
        "plt.savefig('lsa_confusion_matrix.png')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3p7OZ06hvKOs"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "print(\"\\nRunning LDA for topic-based sentiment classification...\")\n",
        "\n",
        "# Vectorize using CountVectorizer (LDA works on raw counts, not TF-IDF)\n",
        "vectorizer = CountVectorizer(\n",
        "    max_df=0.95,\n",
        "    min_df=5,\n",
        "    max_features=3000,\n",
        "    stop_words='english'\n",
        ")\n",
        "X_counts = vectorizer.fit_transform(balanced_df['cleaned_review'])\n",
        "\n",
        "# Apply LDA\n",
        "n_topics = 30\n",
        "lda_model = LatentDirichletAllocation(\n",
        "    n_components=n_topics,\n",
        "    max_iter=10,\n",
        "    learning_method='online',\n",
        "    random_state=RANDOM_SEED,\n",
        "    evaluate_every=-1,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "X_topics = lda_model.fit_transform(X_counts)\n",
        "print(f\"LDA topic distribution shape: {X_topics.shape}\")\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_topics,\n",
        "    balanced_df['sentiment_label'].values,\n",
        "    test_size=0.2,\n",
        "    random_state=RANDOM_SEED,\n",
        "    stratify=balanced_df['sentiment_label']\n",
        ")\n",
        "\n",
        "# Train a classifier on LDA features\n",
        "print(\"\\nTraining classifier on LDA topic distributions...\")\n",
        "clf = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=RANDOM_SEED)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate\n",
        "y_pred = clf.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(f\"\\nLDA + Logistic Regression Results:\")\n",
        "print(f\"Accuracy: {acc:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=['Negative', 'Neutral', 'Positive']))\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Purples',\n",
        "            xticklabels=['Negative', 'Neutral', 'Positive'],\n",
        "            yticklabels=['Negative', 'Neutral', 'Positive'])\n",
        "plt.title('LDA + Logistic Regression Confusion Matrix', fontsize=15)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.tight_layout()\n",
        "plt.savefig('lda_confusion_matrix.png')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ehIJ4_UkJLu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "\n",
        "# Download stopwords if not already done\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Random seed for reproducibility\n",
        "RANDOM_SEED = 100\n",
        "\n",
        "# ============================\n",
        "# Load your dataset\n",
        "# ============================\n",
        "\n",
        "# Ensure your dataset is loaded properly\n",
        "# Must contain 'cleaned_review' and 'sentiment_label'\n",
        "# Example:\n",
        "# balanced_df = pd.read_csv('your_dataset.csv')\n",
        "# assert 'cleaned_review' in balanced_df.columns\n",
        "# assert 'sentiment_label' in balanced_df.columns\n",
        "\n",
        "# ============================\n",
        "# LDA + Logistic Regression\n",
        "# ============================\n",
        "\n",
        "print(\"\\nRunning LDA for topic-based sentiment classification...\")\n",
        "\n",
        "# Vectorize using CountVectorizer (raw counts)\n",
        "vectorizer = CountVectorizer(\n",
        "    max_df=0.90,\n",
        "    min_df=3,\n",
        "    max_features=500,\n",
        "    stop_words=stopwords.words('english'),\n",
        "    ngram_range=(1, 2)  # include bigrams\n",
        ")\n",
        "X_counts = vectorizer.fit_transform(balanced_df['cleaned_review'])\n",
        "\n",
        "# Fit LDA\n",
        "n_topics = 25  # Lower topic count for better generalization\n",
        "lda_model = LatentDirichletAllocation(\n",
        "    n_components=n_topics,\n",
        "    max_iter=20,  # Increased iterations\n",
        "    learning_method='online',\n",
        "    learning_decay=0.7,\n",
        "    evaluate_every=1,\n",
        "    random_state=RANDOM_SEED,\n",
        "    n_jobs=-1\n",
        ")\n",
        "X_topics = lda_model.fit_transform(X_counts)\n",
        "print(f\"LDA topic distribution shape: {X_topics.shape}\")\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_topics,\n",
        "    balanced_df['sentiment_label'].values,\n",
        "    test_size=0.5,\n",
        "    random_state=RANDOM_SEED,\n",
        "    stratify=balanced_df['sentiment_label']\n",
        ")\n",
        "\n",
        "# Train classifier\n",
        "print(\"\\nTraining Logistic Regression on LDA topic distributions...\")\n",
        "clf = LogisticRegression(\n",
        "    max_iter=100,\n",
        "    class_weight='balanced',\n",
        "    solver='lbfgs',\n",
        "    random_state=RANDOM_SEED,\n",
        "    C=2.0  # Increased regularization strength\n",
        ")\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate\n",
        "y_pred = clf.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(f\"\\nLDA + Logistic Regression Results:\")\n",
        "print(f\"Accuracy: {acc:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(\n",
        "    y_test,\n",
        "    y_pred,\n",
        "    target_names=['Negative', 'Neutral', 'Positive']\n",
        "))\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Purples',\n",
        "            xticklabels=['Negative', 'Neutral', 'Positive'],\n",
        "            yticklabels=['Negative', 'Neutral', 'Positive'])\n",
        "plt.title('LDA + Logistic Regression Confusion Matrix', fontsize=15)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.tight_layout()\n",
        "plt.savefig('lda_confusion_matrix.png')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kaz7-JLnvRWJ"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"\\nVectorizing text with TF-IDF for Naive Bayes...\")\n",
        "vectorizer = TfidfVectorizer(\n",
        "    ngram_range=(1, 2),\n",
        "    max_features=5000,\n",
        "    min_df=5,\n",
        "    max_df=0.9,\n",
        "    stop_words='english'\n",
        ")\n",
        "\n",
        "X = vectorizer.fit_transform(balanced_df['cleaned_review'])\n",
        "y = balanced_df['sentiment_label'].values\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.1,\n",
        "    stratify=y,\n",
        "    random_state=RANDOM_SEED\n",
        ")\n",
        "\n",
        "# Train Naive Bayes model\n",
        "print(\"\\nTraining Multinomial Naive Bayes model...\")\n",
        "nb_model = MultinomialNB()\n",
        "nb_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = nb_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(\"\\nMultinomial Naive Bayes Results:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=['Negative', 'Neutral', 'Positive']))\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='YlGnBu',\n",
        "            xticklabels=['Negative', 'Neutral', 'Positive'],\n",
        "            yticklabels=['Negative', 'Neutral', 'Positive'])\n",
        "plt.title('Confusion Matrix - Naive Bayes', fontsize=15)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.tight_layout()\n",
        "plt.savefig('naive_bayes_confusion_matrix.png')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9oPFI9Zv27h"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"\\nVectorizing text with TF-IDF for SVM...\")\n",
        "vectorizer = TfidfVectorizer(\n",
        "    ngram_range=(1, 2),\n",
        "    max_features=7000,\n",
        "    min_df=5,\n",
        "    max_df=0.9,\n",
        "    stop_words='english'\n",
        ")\n",
        "\n",
        "X = vectorizer.fit_transform(balanced_df['cleaned_review'])\n",
        "y = balanced_df['sentiment_label'].values\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.1,\n",
        "    stratify=y,\n",
        "    random_state=RANDOM_SEED\n",
        ")\n",
        "\n",
        "# Train the SVM\n",
        "print(\"\\nTraining LinearSVC for sentiment classification...\")\n",
        "svm_model = LinearSVC(C=1.0, class_weight='balanced', max_iter=5000)\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = svm_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(\"\\nLinear SVM Results:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=['Negative', 'Neutral', 'Positive']))\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='YlGnBu',\n",
        "            xticklabels=['Negative', 'Neutral', 'Positive'],\n",
        "            yticklabels=['Negative', 'Neutral', 'Positive'])\n",
        "plt.title('Confusion Matrix - Linear SVM', fontsize=15)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.tight_layout()\n",
        "plt.savefig('svm_confusion_matrix.png')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JhiR_Y6uwd0W"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"\\nVectorizing text using TF-IDF for Random Forest...\")\n",
        "vectorizer = TfidfVectorizer(\n",
        "    ngram_range=(1, 2),\n",
        "    max_features=10000,\n",
        "    min_df=5,\n",
        "    max_df=0.85,\n",
        "    stop_words='english'\n",
        ")\n",
        "\n",
        "X = vectorizer.fit_transform(balanced_df['cleaned_review'])\n",
        "y = balanced_df['sentiment_label'].values\n",
        "\n",
        "# Split into train/test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    stratify=y,\n",
        "    random_state=RANDOM_SEED\n",
        ")\n",
        "\n",
        "print(\"\\nTraining Random Forest Classifier...\")\n",
        "rf_model = RandomForestClassifier(\n",
        "    n_estimators=300,\n",
        "    max_depth=50,\n",
        "    class_weight='balanced',\n",
        "    random_state=RANDOM_SEED,\n",
        "    n_jobs=-1\n",
        ")\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate\n",
        "y_pred = rf_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(f\"\\nRandom Forest Results:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=['Negative', 'Neutral', 'Positive']))\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='BuGn',\n",
        "            xticklabels=['Negative', 'Neutral', 'Positive'],\n",
        "            yticklabels=['Negative', 'Neutral', 'Positive'])\n",
        "plt.title('Confusion Matrix - Random Forest', fontsize=15)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.tight_layout()\n",
        "plt.savefig('rf_confusion_matrix.png')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLR9CoKYvYjE"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"\\nVectorizing text using TF-IDF for Random Forest...\")\n",
        "vectorizer = TfidfVectorizer(\n",
        "    ngram_range=(1, 2),\n",
        "    max_features=100000,\n",
        "    min_df=5,\n",
        "    max_df=0.9,\n",
        "    stop_words='english'\n",
        ")\n",
        "\n",
        "X = vectorizer.fit_transform(balanced_df['cleaned_review'])\n",
        "y = balanced_df['sentiment_label'].values\n",
        "\n",
        "# Split into train/test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.1,\n",
        "    stratify=y,\n",
        "    random_state=RANDOM_SEED\n",
        ")\n",
        "\n",
        "print(\"\\nTraining Random Forest Classifier...\")\n",
        "rf_model = RandomForestClassifier(\n",
        "    n_estimators=300,\n",
        "    max_depth=500,\n",
        "    class_weight='balanced',\n",
        "    random_state=RANDOM_SEED,\n",
        "    n_jobs=-1\n",
        ")\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate\n",
        "y_pred = rf_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(f\"\\nRandom Forest Results:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=['Negative', 'Neutral', 'Positive']))\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='BuGn',\n",
        "            xticklabels=['Negative', 'Neutral', 'Positive'],\n",
        "            yticklabels=['Negative', 'Neutral', 'Positive'])\n",
        "plt.title('Confusion Matrix - Random Forest', fontsize=15)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.tight_layout()\n",
        "plt.savefig('rf_confusion_matrix.png')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o26OxqZLcgSv"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Vectorizing with TF-IDF\n",
        "print(\"\\nVectorizing text with TF-IDF for Stacked Ensemble...\")\n",
        "vectorizer = TfidfVectorizer(\n",
        "    ngram_range=(1, 2),\n",
        "    max_features=7000,\n",
        "    min_df=5,\n",
        "    max_df=0.85,\n",
        "    stop_words='english'\n",
        ")\n",
        "\n",
        "X = vectorizer.fit_transform(balanced_df['cleaned_review'])\n",
        "y = balanced_df['sentiment_label'].values\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.25,\n",
        "    stratify=y,\n",
        "    random_state=RANDOM_SEED\n",
        ")\n",
        "\n",
        "# Define base learners\n",
        "base_learners = [\n",
        "    ('nb', MultinomialNB()),\n",
        "    ('rf', RandomForestClassifier(n_estimators=100, random_state=RANDOM_SEED)),\n",
        "    ('svm', LinearSVC(C=1.0, class_weight='balanced', max_iter=5000))\n",
        "]\n",
        "\n",
        "# Define meta learner\n",
        "meta_learner = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Build stacked ensemble\n",
        "stacked_model = StackingClassifier(\n",
        "    estimators=base_learners,\n",
        "    final_estimator=meta_learner,\n",
        "    cv=5,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Train model\n",
        "print(\"\\nTraining Stacked Ensemble for sentiment classification...\")\n",
        "stacked_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = stacked_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(\"\\nStacked Ensemble Results:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=['Negative', 'Neutral', 'Positive']))\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='YlGnBu',\n",
        "            xticklabels=['Negative', 'Neutral', 'Positive'],\n",
        "            yticklabels=['Negative', 'Neutral', 'Positive'])\n",
        "plt.title('Confusion Matrix - Stacked Ensemble', fontsize=15)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.tight_layout()\n",
        "plt.savefig('stacked_confusion_matrix.png')\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZltAnDTwPawg"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Vectorizing with TF-IDF\n",
        "print(\"\\nVectorizing text with TF-IDF for Stacked Ensemble...\")\n",
        "vectorizer = TfidfVectorizer(\n",
        "    ngram_range=(1, 2),\n",
        "    max_features=9000,\n",
        "    min_df=5,\n",
        "    max_df=0.95,\n",
        "    stop_words='english'\n",
        ")\n",
        "\n",
        "X = vectorizer.fit_transform(balanced_df['cleaned_review'])\n",
        "y = balanced_df['sentiment_label'].values\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.1,\n",
        "    stratify=y,\n",
        "    random_state=RANDOM_SEED\n",
        ")\n",
        "\n",
        "# Define base learners\n",
        "base_learners = [\n",
        "    ('nb', MultinomialNB()),\n",
        "    ('rf', RandomForestClassifier(n_estimators=100, random_state=RANDOM_SEED)),\n",
        "    ('svm', LinearSVC(C=1.0, class_weight='balanced', max_iter=5000))\n",
        "]\n",
        "\n",
        "# Define meta learner\n",
        "meta_learner = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Build stacked ensemble\n",
        "stacked_model = StackingClassifier(\n",
        "    estimators=base_learners,\n",
        "    final_estimator=meta_learner,\n",
        "    cv=5,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Train model\n",
        "print(\"\\nTraining Stacked Ensemble for sentiment classification...\")\n",
        "stacked_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = stacked_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(\"\\nStacked Ensemble Results:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=['Negative', 'Neutral', 'Positive']))\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='YlGnBu',\n",
        "            xticklabels=['Negative', 'Neutral', 'Positive'],\n",
        "            yticklabels=['Negative', 'Neutral', 'Positive'])\n",
        "plt.title('Confusion Matrix - Stacked Ensemble', fontsize=15)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.tight_layout()\n",
        "plt.savefig('stacked_confusion_matrix.png')\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7fc_k4uaiIcD"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
        "import xgboost as xgb\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\nVectorizing text with TF-IDF for XGBoost...\")\n",
        "vectorizer = TfidfVectorizer(\n",
        "    ngram_range=(1, 2),\n",
        "    max_features=8000,\n",
        "    min_df=5,\n",
        "    max_df=0.85,\n",
        "    stop_words='english'\n",
        ")\n",
        "\n",
        "X = vectorizer.fit_transform(balanced_df['cleaned_review'])\n",
        "y = balanced_df['sentiment_label'].values\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.5,\n",
        "    stratify=y,\n",
        "    random_state=RANDOM_SEED\n",
        ")\n",
        "\n",
        "# Train XGBoost model\n",
        "print(\"\\nTraining XGBoost for sentiment classification...\")\n",
        "xgb_model = xgb.XGBClassifier(\n",
        "    objective='multi:softmax',\n",
        "    num_class=3,  # Change if you have a different number of classes\n",
        "    eval_metric='mlogloss',\n",
        "    use_label_encoder=False,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.1,\n",
        "    n_estimators=100,\n",
        "    random_state=RANDOM_SEED\n",
        ")\n",
        "\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = xgb_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(\"\\nXGBoost Results:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=['Negative', 'Neutral', 'Positive']))\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='YlGnBu',\n",
        "            xticklabels=['Negative', 'Neutral', 'Positive'],\n",
        "            yticklabels=['Negative', 'Neutral', 'Positive'])\n",
        "plt.title('Confusion Matrix - XGBoost', fontsize=15)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.tight_layout()\n",
        "plt.savefig('xgboost_confusion_matrix.png')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YwIjDq5YsyvO"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
        "import xgboost as xgb\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\nVectorizing text with TF-IDF for XGBoost...\")\n",
        "vectorizer = TfidfVectorizer(\n",
        "    ngram_range=(1, 2),\n",
        "    max_features=80000,\n",
        "    min_df=5,\n",
        "    max_df=0.9,\n",
        "    stop_words='english'\n",
        ")\n",
        "\n",
        "X = vectorizer.fit_transform(balanced_df['cleaned_review'])\n",
        "y = balanced_df['sentiment_label'].values\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.1,\n",
        "    stratify=y,\n",
        "    random_state=RANDOM_SEED\n",
        ")\n",
        "\n",
        "# Train XGBoost model\n",
        "print(\"\\nTraining XGBoost for sentiment classification...\")\n",
        "xgb_model = xgb.XGBClassifier(\n",
        "    objective='multi:softmax',\n",
        "    num_class=3,  # Change if you have a different number of classes\n",
        "    eval_metric='mlogloss',\n",
        "    use_label_encoder=False,\n",
        "    max_depth=9,\n",
        "    learning_rate=0.3,\n",
        "    n_estimators=1000,\n",
        "    random_state=RANDOM_SEED\n",
        ")\n",
        "\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = xgb_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(\"\\nXGBoost Results:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=['Negative', 'Neutral', 'Positive']))\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='YlGnBu',\n",
        "            xticklabels=['Negative', 'Neutral', 'Positive'],\n",
        "            yticklabels=['Negative', 'Neutral', 'Positive'])\n",
        "plt.title('Confusion Matrix - XGBoost', fontsize=15)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.tight_layout()\n",
        "plt.savefig('xgboost_confusion_matrix.png')\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}